{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_sep_batch",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXXQckPqPUcOKlCHMEbKkb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eric88525/Tbrain_NLP_game/blob/master/train_sep_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIjhvFyLXU9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7595b0c2-1c15-480e-bd3a-b1e9d491078b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/bin/bash: google-drive-ocamlfuse: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5cWZWqHXVLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "48be2128-5653-4b0f-ec46-23545bd35c79"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install opencc\n",
        "!pip install pyprind\n",
        "!pip install zhon\n",
        "!pip install -U ckiptagger[tfgpu,gdown]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: opencc in /usr/local/lib/python3.6/dist-packages (1.1.1.post1)\n",
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.6/dist-packages (2.11.2)\n",
            "Requirement already satisfied: zhon in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already up-to-date: ckiptagger[gdown,tfgpu] in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied, skipping upgrade: gdown; extra == \"gdown\" in /usr/local/lib/python3.6/dist-packages (from ckiptagger[gdown,tfgpu]) (3.6.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\" in /usr/local/lib/python3.6/dist-packages (from ckiptagger[gdown,tfgpu]) (1.15.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.12.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (49.1.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teRHvOYyXbNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02nMffqpeCRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e21c8ab-a961-4a44-dcd8-9bc2894ff782"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from transformers import *\n",
        "import pandas as pd\n",
        "import ast\n",
        "import copy\n",
        "import os\n",
        "from time import strftime,gmtime\n",
        "from opencc import OpenCC\n",
        "import pyprind\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import re\n",
        "from zhon.hanzi import non_stops,stops\n",
        "import numpy as np\n",
        "import random\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imxxfLbnrR5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f45ee20-b95c-4d0e-9d18-59a3232d30f5"
      },
      "source": [
        "!cd /content/drive/My Drive/Colab Notebooks/TBrain/nosep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deUCQ8WkzX81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(pred, ans):\n",
        "    if bool(pred) is not bool(ans):\n",
        "        return 0\n",
        "    elif not pred and not ans:\n",
        "        return 1\n",
        "    else:\n",
        "        pred = set(pred)\n",
        "        ans = set(ans)\n",
        "        interaction_len = len(pred & ans)\n",
        "        if interaction_len == 0:\n",
        "            return 0\n",
        "\n",
        "        pred_len = len(pred)\n",
        "        ans_len = len(ans)\n",
        "        return 2 / (pred_len / interaction_len + ans_len / interaction_len)\n",
        "\n",
        "\n",
        "def eval_all(pred_list, ans_list):\n",
        "    assert len(pred_list) == len(ans_list)\n",
        "    return sum(eval(p, a) for p, a in zip(pred_list, ans_list)) / len(pred_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWpwu856XTO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mydata_nosep():\n",
        "    def __init__(self,train_path,test_path):\n",
        "\n",
        "        self.cc = OpenCC('t2s')\n",
        "        train_data = pd.read_csv(train_path)\n",
        "        test_data = pd.read_csv(test_path)\n",
        "        # CONTENT / NAME / CKIPNAME\n",
        "        train_x = [ self.clean_string(i) for i in train_data['full_content'].values.tolist()]\n",
        "        train_y = [ self.name_list(i) for i in train_data['name'].values.tolist()]\n",
        "        train_z = [ self.name_list(i) for i in train_data['ckip_names'].values.tolist() ]\n",
        "\n",
        "        # CONTENT / NAME\n",
        "        test_x = [self.clean_string(i) for i in test_data['full_content'].values.tolist()]\n",
        "        self.test_y = [self.name_list(i) for i in test_data['name'].values.tolist()]\n",
        "        #test_z = [self.name_list(i) for i in test_data['ckip_names'].values.tolist()]\n",
        "\n",
        "        self.train = [] # CONTENT / NAME / (CKIP-NAME)\n",
        "        self.test = []  # CONTENT / NAME\n",
        "\n",
        "        \n",
        "        qs = 0 \n",
        "        for i in range(len(train_x)):\n",
        "          if len(train_y[i]) == 0:\n",
        "            #self.train.append([train_x[i],[],[]])\n",
        "            continue\n",
        "          q = []\n",
        "          a = []\n",
        "          for n in train_y[i]:\n",
        "            qs += 1\n",
        "            self.train.append([train_x[i],n,1])\n",
        "          for n in train_z[i]-train_y[i]:\n",
        "            if len(n)==1: # remove the ckip name len is 1\n",
        "              continue\n",
        "            qs += 1\n",
        "            self.train.append([train_x[i],n,0])              \n",
        "\n",
        "        for i in range(len(test_x)):\n",
        "          self.test.append([test_x[i],self.test_y[i],])\n",
        "\n",
        "\n",
        "        print(f'Train: {len(self.train)} Test: {len(self.test)} Questions: {qs}')\n",
        "\n",
        "    def name_list(self,name_list_str):\n",
        "        ls = ast.literal_eval(name_list_str)\n",
        "        res = []\n",
        "        cc = OpenCC('t2s')\n",
        "        for n in ls:\n",
        "          res.append(cc.convert(n))\n",
        "        return set(res)        \n",
        "    def clean_string(self,content):\n",
        "      content = content.replace('\\n','。').replace('\\t','，').replace('!', '！').replace('?', '？')# erease white space cause English name error\n",
        "      content = re.sub(\"[+\\.\\/_,$%●▼►^*(+\\\"\\']+|[+——~@#￥%……&*（）★]\", \"\",content)\n",
        "      content = re.sub(r\"[%s]+\" %stops, \"。\",content)\n",
        "      content = self.cc.convert(content)\n",
        "      return content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OGS78UM3NW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self,data,model_type):\n",
        "      self.data = data\n",
        "      self.tokenizer = BertTokenizer.from_pretrained(model_type)\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "      question , paragraph ,label = self.data[idx][1] , self.data[idx][0],self.data[idx][2]\n",
        "      token_tensor = self.tokenizer.encode_plus(question ,paragraph,max_length=512,truncation=True,pad_to_max_length=True)\n",
        "      label_tensor = torch.Tensor([label])\n",
        "      # token / segment / mask / label\n",
        "      return  torch.tensor(token_tensor['input_ids']), torch.tensor( token_tensor['token_type_ids']) , torch.tensor( token_tensor['attention_mask'] ),label_tensor\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egtz9KVfigNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bertwwm(nn.Module):\n",
        "    def __init__(self,model_name):\n",
        "        super(bertwwm,self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained(model_name)\n",
        "        self.bi_decoder = nn.Sequential(     \n",
        "            nn.Linear(768,1)\n",
        "            ,nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self,input_ids):\n",
        "        all_hidden_states, all_attentions = self.bert_model(input_ids)[-2:]\n",
        "        binary = self.bi_decoder(all_attentions).reshape(1)\n",
        "        return binary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DOdMn1BYQVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bertwwmQA(nn.Module):\n",
        "    def __init__(self,model_name,config):\n",
        "        super(bertwwmQA,self).__init__()\n",
        "        #self.bert_model = BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\")\n",
        "        \n",
        "        self.bert_model = BertModel.from_pretrained(model_name,config = config)\n",
        "        self.bi_decoder = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size,config.hidden_size)\n",
        "            ,nn.Dropout(0.1)\n",
        "            ,nn.ReLU()\n",
        "            ,nn.Linear(config.hidden_size,1)\n",
        "            ,nn.Sigmoid()\n",
        "        )\n",
        "        #self.start()\n",
        "\n",
        "    def start(self):\n",
        "      nn.init.xavier_uniform_(self.bi_decoder[0].weight)\n",
        "      nn.init.constant_(self.bi_decoder[0].bias, 0)\n",
        "      nn.init.xavier_uniform_(self.bi_decoder[3].weight)\n",
        "      nn.init.constant_(self.bi_decoder[3].bias, 0)\n",
        "\n",
        "    def forward(self,input_ids=None,attention_mask=None,token_type_ids=None):\n",
        "        print(f'receive input_ids {input_ids}')\n",
        "\n",
        "        cls = self.bert_model(input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)[1]\n",
        "        binary = self.bi_decoder(cls)\n",
        "        return binary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeU_ooqwpN8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model,data,device,ws,pos,ner,model_name):\n",
        "    #b_modelname = 'bertWWM_BI_16_27_53.pt'\n",
        "    #bin_model = bertwwm().to(device)\n",
        "    #bin_model.load_state_dict(torch.load(f'saved_models/{b_modelname}'))\n",
        "    print('Testing...')\n",
        "    test_num = len(data.test)\n",
        "    #criterion = nn.BCELoss()\n",
        "    #b_tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model.eval()\n",
        "    print(f'Testing data: {test_num}')\n",
        "    c_to_tw = OpenCC('s2t') # chi to tw\n",
        "    tw_to_c = OpenCC('t2s')\n",
        "    label_count = 0\n",
        "    all_predlist = []\n",
        "    all_labellist = data.test_y\n",
        "    with torch.no_grad():\n",
        "      for content,nlabel in data.test:\n",
        "        if len(nlabel) == 0:\n",
        "          continue\n",
        "       # b_input_ids = torch.tensor([b_tokenizer.encode(str(content),max_length=512,truncation=True,pad_to_max_length=True)]).to(device)   \n",
        "        #print(b_input_ids)\n",
        "       # pred = bin_model(b_input_ids)\n",
        "        #print(pred.item())\n",
        "     #   if pred.item() < 0.4:\n",
        "      #    all_predlist.append([])\n",
        "       #   continue\n",
        "        #if len(nlabel) == 0:\n",
        "        #  continue\n",
        "        if len(content)>512:\n",
        "          content = content[:512] \n",
        "        label_count += 1\n",
        "        ckip_nlist = []\n",
        "        pred_nlist = []\n",
        "        ws_results = ws([c_to_tw.convert(content)])\n",
        "        pos_results = pos(ws_results)\n",
        "        ner_results = ner(ws_results, pos_results)\n",
        "        for name in ner_results[0]:\n",
        "          if name[2] == 'PERSON':\n",
        "            ckip_nlist.append(tw_to_c.convert(name[3]))\n",
        "        ckip_nlist = set(ckip_nlist)\n",
        "        for ckip_name in ckip_nlist:\n",
        "          tk = tokenizer.encode(str(content),str(ckip_name),max_length=512,truncation=True,pad_to_max_length=True)\n",
        "         # tk = tokenizer.encode(str(content),str(ckip_name),max_length=512,truncation=True,pad_to_max_length=True)\n",
        "          input_ids = torch.tensor([tk]).to(device)\n",
        "          pred = model(input_ids).to('cpu')\n",
        "          if pred.item()>0.3:\n",
        "            pred_nlist.append( [ckip_name,pred.item()])\n",
        "        all_predlist.append(pred_nlist)\n",
        "        print(f' CKIP {ckip_nlist} PRED {pred_nlist} LABEL {nlabel}')\n",
        "    return eval(all_predlist,all_labellist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtksFQ2ghOFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testBIN(model,data,device,ws,pos,ner,model_name):\n",
        "    print('Testing...')\n",
        "    acc = 0\n",
        "    total = len(data.test)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    with torch.no_grad():\n",
        "      for content,name in data.test:\n",
        "        input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True,pad_to_max_length=True)]).to(device)   \n",
        "        b_pred = model(input_ids).to(device) \n",
        "        if b_pred.item() < 0.4 and len(name) == 0:\n",
        "          acc +=1\n",
        "        elif b_pred.item() > 0.4 and len(name):\n",
        "          acc +=1\n",
        "        print(f'C: {content[:20]} Name: {name} Pred: {b_pred.item()}')\n",
        "    print(f'ALL {total} ACC {acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlJK2HQ8kATR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b1b33966-7312-4214-cb96-654aaf5f6239"
      },
      "source": [
        "\"\"\"\n",
        "config = BertConfig.from_pretrained(model_type, output_hidden_states=True)\n",
        "model = bertwwmQA(model_type,config)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "for data in trainLoader:\n",
        "  token , segment , mask , label = data\n",
        "  print(type(token),token.shape)\n",
        "  print(type(segment),segment.shape)\n",
        "  print(type(mask),mask.shape)\n",
        "  print(type(label),label.shape)\n",
        "  pred = model(input_ids=token,attention_mask=mask,token_type_ids=segment)\n",
        "  print(criterion(pred,label))\n",
        "  break\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nconfig = BertConfig.from_pretrained(model_type, output_hidden_states=True)\\nmodel = bertwwmQA(model_type,config)\\ncriterion = nn.BCELoss()\\n\\nfor data in trainLoader:\\n  token , segment , mask , label = data\\n  print(type(token),token.shape)\\n  print(type(segment),segment.shape)\\n  print(type(mask),mask.shape)\\n  print(type(label),label.shape)\\n  pred = model(input_ids=token,attention_mask=mask,token_type_ids=segment)\\n  print(criterion(pred,label))\\n  break\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrFxvpVYYQe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(trainLoader,lr_rate,w_d,device,model_type,epoches):\n",
        "  config = BertConfig.from_pretrained(model_type, output_hidden_states=True)\n",
        "  model = bertwwmQA(model_type,config).to(device)\n",
        "  parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = AdamW(parameters, lr=lr_rate, weight_decay=w_d)\n",
        "  criterion = nn.BCELoss()\n",
        "  for e in range(epoches):\n",
        "    loss,i = 0,0\n",
        "    for data in trainLoader:\n",
        "      i+=1\n",
        "      token , segment , mask , label = data\n",
        "      pred = model(input_ids=token,attention_mask=mask,token_type_ids=segment)\n",
        "      batch_loss = criterion(pred,label)\n",
        "      loss += batch_loss\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.step()\n",
        "    print(f'Epoches: {e} Loss {loss} AVG: {loss/i}')\n",
        "  best_model = copy.deepcopy(model.state_dict())\n",
        "  return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UgMdGyyd0dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainBinary(data,lr_rate,w_d,device,model_type):\n",
        "  model = bertwwm(model_type).to(device)\n",
        "  parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = AdamW(parameters, lr=lr_rate, weight_decay=w_d)\n",
        "  criterion = nn.BCELoss()\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_type)\n",
        "  optimizer.zero_grad()\n",
        "  loss = 0\n",
        "  model.train()\n",
        "  for epoches in range(10):\n",
        "    print(f'Epoches: {epoches}')\n",
        "    i = 0\n",
        "    loss = 0\n",
        "    for content,question,ans in data.train: \n",
        "      i += 1\n",
        "      input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True,pad_to_max_length=True)]).to(device)\n",
        "      pred = model(input_ids)\n",
        "      if len(question)!=0: \n",
        "        b_label = torch.Tensor([1]).to(device)\n",
        "      elif len(question) == 0:\n",
        "        b_label = torch.Tensor([0]).to(device)\n",
        "      a_loss = criterion(pred,b_label)\n",
        "      loss += a_loss\n",
        "      a_loss.backward()\n",
        "      del input_ids\n",
        "      del b_label\n",
        "      #print(f'i: {i} Content:{content[:10]} Q: {question} Label {b_label} Pred:{pred} Loss:{a_loss}')\n",
        "      if i % 4 == 0:\n",
        "        print(f'B LOSS is {loss/4}')\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "  best_model = copy.deepcopy(model.state_dict())\n",
        "  return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PYG3_UWreYn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68aa3c73-4a03-486f-a6dd-e5947c4eaef8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpoz7eIbbRHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "79d6e8c2-3017-486f-f82e-4dbb23282f3e"
      },
      "source": [
        "data = mydata_nosep('./data0/tbrain_train.csv','./data0/tbrain_test.csv')\n",
        "train_ds = TrainDataset(mydata.train,model_type)\n",
        "trainLoader = DataLoader(dds, batch_size=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d5045d8203bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmydata_nosep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data0/tbrain_train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./data0/tbrain_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4172b0decc71>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_path, test_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenCC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't2s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# CONTENT / NAME / CKIPNAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data0/tbrain_train.csv does not exist: './data0/tbrain_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywp1kKxVWSbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFRr64FirS8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from ckiptagger import WS, POS, NER\n",
        "ws = WS(\"./data\")\n",
        "pos = POS(\"./data\")\n",
        "ner = NER(\"./data\")\n",
        "print('CKIP finish')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F3jttAwYQom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "mode = 'train_qa'\n",
        "model_type = 'hfl/chinese-roberta-wwm-ext'\n",
        "torch.cuda.empty_cache()  \n",
        "if mode == 'train_qa':\n",
        "  model_type = 'hfl/chinese-bert-wwm'\n",
        "  config = BertConfig.from_pretrained(model_type,output_hidden_states=True)\n",
        "  print('Train QA')\n",
        "  best_model = train(trainLoader,0.001,1e-5,device,model_type,1)\n",
        "  if not os.path.exists('saved_models'):\n",
        "    os.makedirs('saved_models')    \n",
        "  modeltime = strftime('%H_%M_%S', gmtime()) \n",
        "  modelname = 'bertWWM_QA_'+ modeltime\n",
        "  torch.save(best_model, f'saved_models/{modelname}.pt')\n",
        "  print(f'Train end, model name is {modelname}.pt')\n",
        "\n",
        "elif mode == 'testqa':\n",
        "  modelname = 'bertWWM_QA_19_27_44.pt'\n",
        "  test_model = bertwwmQA(model_type).to(device)\n",
        "  test_model.load_state_dict(torch.load(f'saved_models/{modelname}'))\n",
        "  \n",
        "  test(test_model,data,device,ws,pos,ner,model_type)\n",
        "\n",
        "# train binary classfier\n",
        "elif mode == 'trainbin':\n",
        "  model_type = 'hfl/chinese-bert-wwm'\n",
        "  best_model = trainBinary(data,0.005,5e-4,device,model_type)\n",
        "  if not os.path.exists('saved_models'):\n",
        "    os.makedirs('saved_models')    \n",
        "  modeltime = strftime('%H_%M_%S', gmtime()) \n",
        "  modelname = 'bertWWM_BIN_'+ modeltime\n",
        "  torch.save(best_model, f'saved_models/{modelname}.pt')\n",
        "  print(f'Train end, model name is {modelname}.pt')\n",
        "\n",
        "\n",
        "elif mode == 'testbin':\n",
        "  modelname = 'bertWWM_BIN_15_05_01.pt'\n",
        "  model_type = 'hfl/chinese-bert-wwm'\n",
        " # test_model = bertwwm(model_type).to(device)\n",
        "  test_model = bertwwm(model_type).to(device)\n",
        "  test_model.load_state_dict(torch.load(f'saved_models/{modelname}'))\n",
        "  \n",
        "  testBIN(test_model,data,device,ws,pos,ner,model_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR_ATRbmtPB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in data.test[:10]:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O25agBgLg62Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RoBERTa-wwm-ext-large\thfl/chinese-roberta-wwm-ext-large\n",
        "#RoBERTa-wwm-ext\thfl/chinese-roberta-wwm-ext\n",
        "#BERT-wwm-ext\thfl/chinese-bert-wwm-ext\n",
        "#BERT-wwm\thfl/chinese-bert-wwm\n",
        "#RBT3\thfl/rbt3\n",
        "#RBTL3\thfl/rbtl3"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}