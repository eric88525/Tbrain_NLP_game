{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from mydata.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from mydata import mydata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "import copy\n",
    "import os\n",
    "from time import strftime,gmtime\n",
    "from opencc import OpenCC\n",
    "import pyprind\n",
    "\n",
    "# Model\n",
    "class bertwwm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bertwwm,self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "        #self.tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "        self.bi_decoder = nn.Sequential(\n",
    "            nn.Linear(768,1)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,input_ids):\n",
    "        #print(input_ids.shape)\n",
    "        # input a string\n",
    "        all_hidden_states, all_attentions = self.bert_model(input_ids)[-2:]\n",
    "        binary = self.bi_decoder(all_attentions).reshape(1)\n",
    "       # print(binary.shape,binary)\n",
    "        return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data,device):\n",
    "    print('Testing...')\n",
    "    size,loss,acc,not_acc = 0,0,0,0\n",
    "    test_num = len(data.test)\n",
    "    criterion = nn.BCELoss()\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "    model.eval()\n",
    "    print(f'Testing data: {test_num}')\n",
    "    with torch.no_grad():\n",
    "        for content,name in data.test:  \n",
    "            if len(name) is 0:    \n",
    "                label = torch.Tensor([0]).to('cpu')\n",
    "            else:\n",
    "                label = torch.Tensor([1]).to('cpu')\n",
    "            size +=1 \n",
    "            input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True)]).to(device)\n",
    "        #print(input_ids)\n",
    "            pred = model(input_ids).to('cpu')\n",
    "            a_loss = criterion(pred,label) \n",
    "            loss += a_loss\n",
    "            if len(name) is 0 and pred.item() < 0.4:\n",
    "                #print(pred.item())\n",
    "                acc +=1\n",
    "            elif len(name) is not 0 and pred.item() >0.4:\n",
    "                acc +=1    \n",
    "    loss /= test_num\n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr  : learning rate\n",
    "# w_d :weight_decay\n",
    "\n",
    "def train(data,lr_rate ,w_d,device):\n",
    "    model = bertwwm().to(device)\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.Adadelta(parameters, lr=lr_rate, weight_decay=w_d)\n",
    "    criterion = nn.BCELoss()  \n",
    "    #cc = OpenCC('tw2sp')\n",
    "    max_test_acc = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "    i = 0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    pbar = pyprind.ProgBar(len(data.train))\n",
    "    for content,name in data.train:\n",
    "        i +=1 \n",
    "        input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True)]).to(device)\n",
    "        #print(input_ids)\n",
    "        pred = model(input_ids).to('cpu') \n",
    "        if len(name) is 0:    \n",
    "            label = torch.Tensor([0]).to('cpu')\n",
    "        else:\n",
    "            label = torch.Tensor([1]).to('cpu')\n",
    "            \n",
    "        batch_loss = criterion(pred,label)\n",
    "        loss += batch_loss\n",
    "        batch_loss.backward()\n",
    "        #print(f'Train loss {loss}') \n",
    "        if (i+1) % 8 is 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            #print(f'Batch loss is {loss/8}')\n",
    "            loss = 0\n",
    "        pbar.update()\n",
    "        \"\"\"\n",
    "        if (i+1) % 1000 is 0:\n",
    "            test_loss,test_acc = test(model,data,device)\n",
    "            print(f'Test Loss is {test_loss} ACC is {test_acc}')\n",
    "            if test_acc > max_test_acc:\n",
    "                print('Better model!')\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        \"\"\"\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load down\n",
      "Testing...\n",
      "Testing data: 503\n",
      "Test Loss is 0.02215447835624218 ACC is 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "device = torch.device('cuda:0')\n",
    "data = mydata('./train_fix.csv')\n",
    "print('Data load down')\n",
    "mode = 't'\n",
    "\n",
    "if mode is 'train':\n",
    "    best_model = train(data,0.006,5e-5,device)\n",
    "    \n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')    \n",
    "    modeltime = strftime('%H_%M_%S', gmtime()) \n",
    "    modelname = 'bertWWM_'+ modeltime\n",
    "    torch.save(best_model, f'saved_models/{modelname}.pt')\n",
    "    print(f'Train end, model name is {modelname}.pt')\n",
    "    test_model = bertwwm().to(device)\n",
    "    test_model.load_state_dict(torch.load(f'saved_models/{modelname}'))\n",
    "    test_loss,test_acc = test(test_model,data,device)\n",
    "    print(f'Test Loss is {test_loss} ACC is {test_acc}')\n",
    "    \n",
    "else:\n",
    "    modelname = 'bertWWM_06_52_12.pt.pt'\n",
    "    test_model = bertwwm().to(device)\n",
    "    test_model.load_state_dict(torch.load(f'saved_models/{modelname}'))\n",
    "    test_loss,test_acc = test(test_model,data,device)\n",
    "    print(f'Test Loss is {test_loss} ACC is {test_acc}')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bertWWM_06_41_57.pt : 500/503\n",
    "# bertWWM_06_52_12.pt.pt : 500/503"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
