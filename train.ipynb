{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from mydata.ipynb\n",
      "Train:4520 Test:503\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from mydata import mydata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "import copy\n",
    "import os\n",
    "from time import strftime,gmtime\n",
    "from opencc import OpenCC\n",
    "import pyprind\n",
    "\n",
    "# Model\n",
    "class bertwwm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bertwwm,self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "        #self.tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "        self.bi_decoder = nn.Sequential(\n",
    "            nn.Linear(768,1)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.Sigmoid()\n",
    "        )\n",
    "        self.start_Linear = nn.Sequential(\n",
    "            nn.Linear(768,512)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.Sigmoid() \n",
    "        )\n",
    "        self.end_Linear = nn.Sequential(\n",
    "            nn.Linear(768,512)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.Sigmoid() \n",
    "        )\n",
    "    def forward(self,input_ids):\n",
    "        #print(input_ids.shape)\n",
    "        # input a string\n",
    "        all_hidden_states, all_attentions = self.bert_model(input_ids)[-2:]\n",
    "        binary = self.bi_decoder(all_attentions).reshape(1)\n",
    "        s = self.start_Linear(all_attentions).reshape(512)\n",
    "        e = self.end_Linear(all_attentions).reshape(512)\n",
    "       # print(binary.shape,binary)\n",
    "        return binary,s,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class bertwwm_pos(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bertwwm_pos,self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "        #self.tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "        self.start_Linear = nn.Sequential(\n",
    "            nn.Linear(768,512)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.Sigmoid() \n",
    "        )\n",
    "        self.end_Linear = nn.Sequential(\n",
    "            nn.Linear(768,512)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.Sigmoid() \n",
    "        )\n",
    "    def forward(self,input_ids):\n",
    "        #print(input_ids.shape)\n",
    "        # input a string\n",
    "        all_hidden_states, all_attentions = self.bert_model(input_ids)[-2:]\n",
    "        #binary = self.bi_decoder(all_attentions).reshape(1)\n",
    "        s = self.start_Linear(all_attentions).reshape(512)\n",
    "        e = self.end_Linear(all_attentions).reshape(512)\n",
    "       # print(binary.shape,binary)\n",
    "        return s,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test(model,data,device):\\n    print(\\'Testing...\\')\\n    size,loss,acc,not_acc = 0,0,0,0\\n    test_num = len(data.test)\\n    criterion = nn.BCELoss()\\n    tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\\n    model.eval()\\n    print(f\\'Testing data: {test_num}\\')\\n    with torch.no_grad():\\n        for content,name,s,e in data.test:  \\n            if len(name) is 0:    \\n                label = torch.Tensor([0]).to(\\'cpu\\')\\n            else:\\n                label = torch.Tensor([1]).to(\\'cpu\\')\\n            size +=1 \\n            input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True)]).to(device)\\n            b_pred,s_pred,e_pred = model(input_ids).to(\\'cpu\\')\\n            a_loss = criterion(pred,label) \\n            loss += a_loss\\n            if len(name) is 0 and pred.item() < 0.4:\\n                #print(pred.item())\\n                acc +=1\\n            elif len(name) is not 0 and pred.item() >0.4:\\n                acc +=1    \\n    loss /= test_num\\n    return loss,acc\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def test(model,data,device):\n",
    "    print('Testing...')\n",
    "    size,loss,acc,not_acc = 0,0,0,0\n",
    "    test_num = len(data.test)\n",
    "    criterion = nn.BCELoss()\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "    model.eval()\n",
    "    print(f'Testing data: {test_num}')\n",
    "    with torch.no_grad():\n",
    "        for content,name,s,e in data.test:  \n",
    "            if len(name) is 0:    \n",
    "                label = torch.Tensor([0]).to('cpu')\n",
    "            else:\n",
    "                label = torch.Tensor([1]).to('cpu')\n",
    "            size +=1 \n",
    "            input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True)]).to(device)\n",
    "            b_pred,s_pred,e_pred = model(input_ids).to('cpu')\n",
    "            a_loss = criterion(pred,label) \n",
    "            loss += a_loss\n",
    "            if len(name) is 0 and pred.item() < 0.4:\n",
    "                #print(pred.item())\n",
    "                acc +=1\n",
    "            elif len(name) is not 0 and pred.item() >0.4:\n",
    "                acc +=1    \n",
    "    loss /= test_num\n",
    "    return loss,acc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data,device):\n",
    "    print('Testing...')\n",
    "    size,loss,acc,not_acc = 0,0,0,0\n",
    "    test_num = len(data.test)\n",
    "    criterion = nn.BCELoss()\n",
    "    cross = nn.CrossEntropyLoss()\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "    model.eval()\n",
    "    print(f'Testing data: {test_num}')\n",
    "    B_loss,S_loss,E_loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for content,name,s,e in data.train:\n",
    "            i +=1 \n",
    "            input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True)]).to(device)   \n",
    "            b_pred,s_pred,e_pred = model(input_ids)\n",
    "            b_pred = b_pred.to('cpu')\n",
    "            s_pred = s_pred.to('cpu')\n",
    "            e_pred = e_pred.to('cpu')\n",
    "        # Binary:\n",
    "            if len(name) is 0:    \n",
    "                b_label = torch.Tensor([0]).to('cpu')\n",
    "            else:\n",
    "                b_label = torch.Tensor([1]).to('cpu')\n",
    "            \n",
    "            if len(name) is 0 and pred.item() < 0.4:\n",
    "                acc +=1\n",
    "            elif len(name) is not 0 and pred.item() >0.4:\n",
    "                acc +=1 \n",
    "        # Start\n",
    "            s_label = [0]*512\n",
    "            for s_ in s:\n",
    "                s_label[s_] = 1\n",
    "            s_label = torch.Tensor(s_label).to('cpu')\n",
    "            print(s_label)\n",
    "        # End\n",
    "            e_label = [0]*512\n",
    "            for e_ in e:\n",
    "                e_label[e_] = 1\n",
    "            e_label = torch.Tensor(e_label).to('cpu')\n",
    "        # count loss\n",
    "            a_b_loss = criterion(b_pred,b_label)\n",
    "            a_s_loss = criterion(s_pred,s_label)\n",
    "            a_e_loss = criterion(e_pred,e_label)\n",
    "            B_loss += a_b_loss\n",
    "            S_loss += a_s_loss\n",
    "            E_loss += a_e_loss\n",
    "            \n",
    "    # Averge        \n",
    "    B_loss /= test_num\n",
    "    S_loss /= test_num\n",
    "    E_loss /= test_num\n",
    "    \n",
    "    return B_loss,S_loss,E_loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr  : learning rate\n",
    "# w_d :weight_decay\n",
    "\n",
    "def train(data,lr_rate ,w_d,device):\n",
    "    model = bertwwm_pos().to(device)\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.Adadelta(parameters, lr=lr_rate, weight_decay=w_d)\n",
    "    criterion = nn.BCELoss()\n",
    "    cross = nn.CrossEntropyLoss()\n",
    "    #cc = OpenCC('tw2sp')\n",
    "    max_test_acc = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "    i = 0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    pbar = pyprind.ProgBar(len(data.train))\n",
    "    for content,name,s,e in data.train:\n",
    "        i +=1 \n",
    "        \n",
    "        input_ids = torch.tensor([tokenizer.encode(str(content),max_length=512,truncation=True)]).to(device)   \n",
    "        \n",
    "        #b_pred,s_pred,e_pred = model(input_ids)\n",
    "        \n",
    "        #b_pred = b_pred.to('cpu')\n",
    "        \n",
    "        s_pred,e_pred = model(input_ids)\n",
    "        s_pred = s_pred.to('cpu')\n",
    "        e_pred = e_pred.to('cpu')\n",
    "               \n",
    "        for task in range(0,3):\n",
    "            # Binary:\n",
    "            if task is -1:\n",
    "                if len(name) is 0:    \n",
    "                    b_label = torch.Tensor([0]).to('cpu')\n",
    "                else:\n",
    "                    b_label = torch.Tensor([1]).to('cpu')\n",
    "                a_b_loss = criterion(b_pred,b_label)\n",
    "                a_b_loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "             # Start\n",
    "            elif task is 1:\n",
    "                s_label = [0]*512\n",
    "                for s_ in s:\n",
    "                    s_label[s_] = 1\n",
    "                s_label = torch.Tensor(s_label).to('cpu')\n",
    "                a_s_loss = criterion(s_pred,s_label)\n",
    "                a_s_loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            elif task is 2:\n",
    "            # End\n",
    "                e_label = [0]*512\n",
    "                for e_ in e:\n",
    "                    e_label[e_] = 1\n",
    "                e_label = torch.Tensor(e_label).to('cpu')\n",
    "                a_e_loss = criterion(e_pred,e_label)\n",
    "                a_e_loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            #optimizer.step()\n",
    "            \n",
    "         # count loss \n",
    "        # backward    \n",
    "        #loss += (a_b_loss + a_s_loss + a_e_loss)/3\n",
    "        #print(f'Train loss {loss}') \n",
    "        #if (i+1) % 4 is 0:\n",
    "        \n",
    "            #print(f'Batch loss is {loss/8}')\n",
    "            #loss = 0\n",
    "        pbar.update()\n",
    "        \"\"\"\n",
    "        if (i+1) % 1000 is 0:\n",
    "            test_loss,test_acc = test(model,data,device)\n",
    "            print(f'Test Loss is {test_loss} ACC is {test_acc}')\n",
    "            if test_acc > max_test_acc:\n",
    "                print('Better model!')\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        \"\"\"\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:4520 Test:503\n",
      "Data load down\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "device = torch.device('cuda:0')\n",
    "data = mydata('./train_fix.csv')\n",
    "print('Data load down')\n",
    "mode = 'train'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 10.76 GiB total capacity; 1.35 GiB already allocated; 6.25 MiB free; 1.43 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8f4af06fa623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-04f66364d4b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, lr_rate, w_d, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0ma_s_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0ma_s_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/adadelta.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 10.76 GiB total capacity; 1.35 GiB already allocated; 6.25 MiB free; 1.43 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if mode is 'train':\n",
    "    best_model = train(data,0.005,5e-5,device)\n",
    "    \n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')    \n",
    "    modeltime = strftime('%H_%M_%S', gmtime()) \n",
    "    modelname = 'bertWWM_'+ modeltime\n",
    "    torch.save(best_model, f'saved_models/{modelname}.pt')\n",
    "    print(f'Train end, model name is {modelname}.pt')\n",
    "    test_model = bertwwm().to(device)\n",
    "    test_model.load_state_dict(torch.load(f'saved_models/{modelname}.pt'))\n",
    "    test_b_loss,test_s_loss,test_e_loss,test_acc = test(test_model,data,device)\n",
    "    print(f'LOSS: B{test_b_loss} S{test_s_loss} E{test_e_loss} ACC is {test_acc}')\n",
    "    \n",
    "else:\n",
    "    modelname = 'bertWWM_07_56_40.pt'\n",
    "    test_model = bertwwm().to(device)\n",
    "    test_model.load_state_dict(torch.load(f'saved_models/{modelname}'))\n",
    "    test_b_loss,test_s_loss,test_e_loss,test_acc = test(test_model,data,device)\n",
    "    print(f'LOSS: B{test_b_loss} S{test_s_loss} E{test_e_loss} ACC is {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bertWWM_06_41_57.pt : 500/503\n",
    "# bertWWM_06_52_12.pt.pt : 500/503\n",
    "# bertWWM_09_01_54.pt : 501/503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cross = nn.BCELoss()\n",
    "x = torch.Tensor([0.3,0.2,0.1])\n",
    "y = torch.Tensor([1,0,0])\n",
    "print(x.shape,y.shape)\n",
    "z = cross(x,y)\n",
    "z\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
